---
title: "20 -  Clustering Based on Statistical Models"
subtitle: "Junvie Pailden"   
author: "SIUE, F2017, Stat 589"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: 
    beamer_presentation:
      theme: "Singapore"
      colortheme: "lily"
      fonttheme: "professionalfonts"
  #ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  options(digits = 3), # round to 3 digits
  echo = TRUE,
  comment = "#",
  fig.path = "figures/",
  fig.height = 4,
  fig.width = 5,
  fig.align = "center",
  cache = FALSE,
  warnings = FALSE,
  message = FALSE)
knitr::opts_knit$set(
  root.dir="data/"
  )
```


## Clustering Based on Statistical Models

* We introduce statistical models that indicate how the collection of
$(p\times1)$ measurements $\mathbf{x}_{j}$, from the $N$ objects,
was generated.  

* Suppose cluster $k$ has proportion $p_{k}$ of the objects and measurements
are generated by a probability density function $f_{k}(\mathbf{x})$.  

* If there are $K$ clusters, the observation vector for a single object
is modeled as arising from the mixing distribution
\[
f_{Mix}(\mathbf{x})=\sum_{k=1}^{K}p_{k}f_{k}(\mathbf{x})
\]
where each $p_{k}\geq0$ and $\sum_{k=1}^{K}p_{k}=1$.

* $f_{Mix}(\mathbf{x})$ is called a mixture of the $K$ distributions
$f_{1}(\mathbf{x}),f_{2}(\mathbf{x}),\ldots,f_{K}(\mathbf{x})$ because
the observation is generated from the component distribution $f_{k}(\mathbf{x})$
with probability $p_{k}$


## Normal Mixture Model

* Suppose the $k$-th component $f_{k}(\mathbf{x})$ is the $N_{p}(\boldsymbol{\mu}_{k},\boldsymbol{\Sigma}_{k})$
density function.  

* The normal mixture model for one observation $\mathbf{x}$ is
\begin{align*}
f_{Mix}(\mathbf{x}|&\boldsymbol{\mu}_{1},\boldsymbol{\Sigma}_{1},  \ldots,\boldsymbol{\mu}_{K},\boldsymbol{\Sigma}_{K})\\
 & =\sum_{k=1}^{K}p_{k}\frac{1}{(2\pi)^{p/2}|\boldsymbol{\Sigma}_{k}|^{1/2}}\exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu}_{k})'\boldsymbol{\Sigma}_{k}^{-1}(\mathbf{x}-\boldsymbol{\mu}_{k})\right)
\end{align*}  

* Clusters generated by this model are ellipsoidal in shape with the
heaviest concentration of observations near the center.


## Normal Mixture Model (cont.)

* The likelihood function, given $N$ objects and fixed \# of clusters
$K$, is
\begin{align*}
L(p_{1},\ldots, & p_{K},\boldsymbol{\mu}_{1},\boldsymbol{\Sigma}_{1},\ldots,\boldsymbol{\mu}_{K},\boldsymbol{\Sigma}_{K})  \\
& = \prod_{j=1}^{N}f_{Mix}(\mathbf{x}_{j}|\boldsymbol{\mu}_{1},\boldsymbol{\Sigma}_{1},\ldots,\boldsymbol{\mu}_{K},\boldsymbol{\Sigma}_{K})\\
= & \prod_{j=1}^{N}\left\{\sum_{k=1}^{K}p_{k}\frac{1}{(2\pi)^{p/2}|\boldsymbol{\Sigma}_{k}|^{1/2}} \right. \\
& \left. \qquad \exp\left(-\frac{1}{2}(\mathbf{x}_{j}-\boldsymbol{\mu}_{k})'\boldsymbol{\Sigma}_{k}^{-1}(\mathbf{x}_{j}-\boldsymbol{\mu}_{k})\right)\right\}
\end{align*}



## Model Selection and Maximum Likelihood Estimates 

1. Obtain the MLE $\hat{p}_{1},\ldots,\hat{p}_{K},\hat{\boldsymbol{\mu}}_{1},\hat{\boldsymbol{\Sigma}}_{1},\ldots,\hat{\boldsymbol{\mu}}{}_{K},\hat{\boldsymbol{\Sigma}}{}_{K}$
for a fixed number of clsuters $K$. Let
\[
L_{max}=L(\hat{p}_{1},\ldots,\hat{p}_{K},\hat{\boldsymbol{\mu}}_{1},\hat{\boldsymbol{\Sigma}}_{1},\ldots,\hat{\boldsymbol{\mu}}{}_{K},\hat{\boldsymbol{\Sigma}}{}_{K})
\]

2. In order to compare models with different numbers of parameters, we
compute and use either the AIC or BIC.  




## Model Selection and Maximum Likelihood Estimates (cont.)


* Akaike Information criterion (AIC)
\[
AIC=2\ln L_{max}-2N\left(K\frac{1}{2}(p+1)(p+2)-1\right)
\]
* Bayesian information criterion (BIC)
\[
BIC=2\ln L_{max}-2\ln(N)\left(K\frac{1}{2}(p+1)(p+2)-1\right)
\]

3. Select the number of clusters and covariance structure with the largest
$AIC$ or $BIC$.


## Structure for the Covariance Matrices $\boldsymbol{\Sigma}_{k}$

* There is difficulty with too many parameters in the mixture model
so simple structures are assumed for the $\boldsymbol{\Sigma}_{k}$.  

* We use the R software package \textbf{mclust} to perform model based
clustering. 


## 

![Structure for the Covariance Matrices](figures/mclust_param.png)


## Model Clustering - Old faithful eruptions data {.allowframebreaks}


```{r 01-lec20}
library(mclust) 
fit.old <- Mclust(faithful) 
summary(fit.old)
```

* In this case, the best model according to BIC is an equal-covariance model with 3 components or clusters. 

* A more detailed summary including the estimated parameters can be obtained with the following code:


## {.allowframebreaks} 

```{r 02-lec20}
summary(fit.old, parameters = TRUE)
plot(faithful, pch = fit.old$classification, 
       col = fit.old$classification,
       cex = 0.7)
```


## Choosing the number of clusters and best covariance structure 

```{r 03-lec20}
plot(fit.old, what = "BIC", cex = 0.3)
```


## 

```{r 04-lec20}
plot(fit.old, what = "classification", cex = 0.5)
```



## Iris Data {.allowframebreaks}

```{r 05-lec20}
fit.iris <- Mclust(iris[,1:4])
summary(fit.iris)
plot(fit.iris, what = "classification", cex = 0.5)
```



## Diabetes Data {.allowframebreaks}

```{r 06-lec20}
data(diabetes) # under mclust package
table(diabetes$class)
X <- diabetes[,-1]
head(X)
clPairs(X, diabetes$class)
```


## Diabetes Data, \# of Clusters {.allowframebreaks}

```{r 07-lec20}
fit.diabetes <- Mclust(X)
plot(fit.diabetes, what  = "BIC", cex = 0.5)
```


## {.allowframebreaks}

```{r}
summary(fit.diabetes, parameters = TRUE)
plot(fit.diabetes, what = "classification", cex = 0.5)
```


